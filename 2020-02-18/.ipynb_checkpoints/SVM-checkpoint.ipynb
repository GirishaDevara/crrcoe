{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "#scikit-learn includes various random sample generators that can be used to build\n",
    "#artificial datasets of controlled size and complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make_blobs create multiclass datasets by allocating each class one or more normally-distributed clusters of points.\n",
    "make_blobs provides greater control regarding the centers and standard deviations of each cluster,and is used to demonstrate clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(make_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=10, centers=2, n_features=2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_blobs(n_samples = 50,centers = 2,random_state = 0,cluster_std = 0.60)\n",
    "plt.scatter(X[:,0],X[:,1],c=y,s=50,cmap = 'autumn')\n",
    "\n",
    "#s : scalar or array_like shape(n,),optional\n",
    "#The marker size in points **2.\n",
    "#c : color,sequence,or sequence of color,optional\n",
    "#size matching both x and y.\n",
    "#A 2D array in which the rows are RGB or RGBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear discriminative classifier would attempt to draw a straight line separating the two sets of dataand therby create a model for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xfit = np.linspace(-1,3.5)\n",
    "plt.scatter(X[:,0],X[:,1],c = y,s = 50,cmap = 'autumn')\n",
    "plt.plot([0.6],[2.1],'x',color = 'r',markeredgewidth = 2,markersize = 10)\n",
    "for m,b in [(1,0.6),(0.5,1.6),(-0.2,2.9)]:\n",
    "    plt.plot(xfit,m*xfit+b,'k')\n",
    "plt.xlim(-1,3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are three very different separators which,nevertheless perfectly discriminate between these samples.Depending on which you choose, a new data point(e.g.,the one marked as 'x' in this plot)will be assigned a different label.Evidently our simple intuition of \"drawing a line between classes\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Maximizing the margin support vector machines offer one way to improve on this.The intuition is to rather than simply drawing a zero-width line between the classes,we can draw around each line a margin of width,up to the nearest point.Here is an example of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(-1,3.5)\n",
    "plt.scatter(X[:,0],X[:,1],c = y,s = 50,cmap = 'autumn')\n",
    "\n",
    "for m,b,d in [(1,0.65,0.33),(0.5,1.6,0.55),(-0.2,2.9,0.2)]:\n",
    "    yfit= m*xfit + b\n",
    "    plt.plot(xfit,yfit,'k')\n",
    "    plt.fill_between(xfit,yfit-d,yfit+d,color ='b',alpha = 0.4)\n",
    "plt.xlim(-1,3.5)\n",
    "#Fill the area in between two hoarizontal curves\n",
    "#this creates one or multiple polygons describing the filling area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result of an actual fit to this data:we will use Scikit-learn's Support Vector Classifier to train an SVM model on this data.We will use linear kernel and set the C parameter to default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel = 'linear',C = 1)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the decision function\n",
    "def plot_svc_decision_function(model,ax=None,plot_support=True):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "#gca means ge current get current axis\n",
    "#current here means it provides a handle to the last active axes.\n",
    "    #create grid to evalute the model\n",
    "    x = np.linspace(xlim[0],xlim[1],30)\n",
    "    y = np.linspace(ylim[0],ylim[1],30)\n",
    "    Y,X = np.meshgrid(y,x)\n",
    "    xy = np.vstack([X.ravel(),Y.ravel()]).T\n",
    "    P= model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    #plot the decision boundary and margins\n",
    "    ax.contour(X,Y,P,colors = 'k',levels = [-1,0,1],alpha = 0.5,\n",
    "               linestyles = ['--','-','--'])\n",
    "    \n",
    "    #plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:,0],\n",
    "                  model.support_vectors_[:,1],\n",
    "                  s = 300,linewidth = 5,facecolors = None)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1],c=y,s=50,cmap='autumn')\n",
    "plot_svc_decision_function(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two datasets are included,realted to red and white Vinho verder wine samples,from north of Portugal.The goal is to model wine quality based on physiochemical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#fixed acidity :most acids involved with wine or fixed or nonvolatile (do not evaporate readily)\n",
    "\n",
    "#volatile acidity: the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste\n",
    "\n",
    "#citric acid:found in small quantities, citric acid can add 'freshness' and flavor to wines\n",
    "\n",
    "#residual sugar: the amount of sugar remaining after fermentation stops, it's rare to find wines with less than 1 gram/liter and wines with greater than 45 grams/liter are considered sweet\n",
    "\n",
    "#chlorides:the amount of salt in the wine\n",
    "\n",
    "#free sulfur dioxide:the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine\n",
    "\n",
    "#total sulfur dioxide:amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine\n",
    "\n",
    "#density: the density of water is close to that of water depending on the percent alcohol and sugar content\n",
    "\n",
    "#pH:describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale\n",
    "\n",
    "#sulphates: a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and antioxidant\n",
    "\n",
    "#alcohol:the percent alcohol content of the wine\n",
    "\n",
    "#quality: output variable (based on sensory data, score between 0 and 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"winequality.csv\")\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality vs sulphates\n",
    "sns.barplot(x='quality',y='sulphates',data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality vs volatile acidity\n",
    "sns.barplot(x='quality',y='volatile acidity',data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality vs alcohol\n",
    "sns.barplot(x='quality',y='alcohol',data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the counts before categorize the quality column\n",
    "d['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize win quality\n",
    "bins =(2,6.5,8)\n",
    "group_names = ['bad','good']\n",
    "categories = pd.cut(d['quality'],bins,labels = group_names)\n",
    "#Bin values into discrete intervals\n",
    "#Use cut function to segment and sort the data values into bins\n",
    "#Useful for going from a continuous variable to a categorical variable\n",
    "d['quality'] =categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after categorize\n",
    "d['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality vs alcohol\n",
    "#more alcohol better red wine\n",
    "sns.barplot(x = 'quality',y='alcohol',data = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality vs volatile acidity\n",
    "#less volatile,better red wine\n",
    "sns.barplot(x='quality',y='volatile acidity',data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data to X and y\n",
    "X = d.drop(['quality'],axis = 1)\n",
    "y = d['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding or dependent variable:quality column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.2,\n",
    "                                                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling to X_train and X_test to classify better\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting kernel svm to the training set\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "classifier = SVC(kernel = 'rbf',random_state = 0)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfold cross validation for improving the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier,X=X_train,\n",
    "                            y=y_train,cv = 100)\n",
    "#cv int cross-validation generator or an iterable,optional\n",
    "#Determines the cross-validation splitting strategy\n",
    "#None,to use default -5-fold cross validation\n",
    "#CV splitter,\n",
    "#An iterable yielding (train, test) splits as arrays of indices.\n",
    "#we can see model's average accuracy\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch for best model and parameters\n",
    "#Exhaustive search over specified parameter values for an estimator\n",
    "#Important members are fit and predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C':[1,10,100,1000],'kernel':['linear']},\n",
    "             {'C':[1,10,100,1000],'kernel':['rbf'],\n",
    "             'gamma':[0.1,0.2,0.4,0.5,0.6,0.7,0.8,0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_accuracy=grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Kernel SVM to the Training set with best parameters\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0, gamma = 0.9)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
