{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donors\n",
    "Things we are going to do in this project:\n",
    "\n",
    "    -->How to identify when preprocessing is needed and how to apply it\n",
    "    -->How to establish a benchmark for a solution to the problem\n",
    "    -->what each of several supervised learning algorithms accomplishes for a specific dataset\n",
    "    -->How to investigate whether a candidate solution model is adequate for the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "# from IPython.display import display\n",
    "# %matplotlib inline\n",
    "data = pd.read_csv(\"donors.csv\")\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation : Data Exploration\n",
    "A cursory investigation of the dataset will determine how many individuals fit into either group,and will tell us about the percentage of these individuals making more than $50,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of records\n",
    "n_records = data.shape[0]\n",
    "\n",
    "#number of records where individual's income is more than $50,000\n",
    "n_greater_50k = data[data['income']=='>50K'].shape[0]\n",
    "\n",
    "#number of records where individual's income is atmost $50,000\n",
    "n_at_most_50k = data[data['income']=='<=50K'].shape[0]\n",
    "\n",
    "#Percentage of individuals whose income is more than $50,000\n",
    "greater_percent = (n_greater_50k/ n_records) * 100\n",
    "\n",
    "#Print the results\n",
    "print('Total number of records: {}'.format(n_records))\n",
    "print('Individuals making more than $50,000: {}'.format(n_greater_50k))\n",
    "print('Individuals making atmost $50,000: {}'.format(n_at_most_50k))\n",
    "print('Percentage of individuals making more than $50,000: {}%'.\n",
    "                 format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Featureset Exploration **\n",
    "\n",
    "* **age**: continuous. \n",
    "* **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "* **education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "* **education-num**: continuous. \n",
    "* **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
    "* **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "* **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "* **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. \n",
    "* **sex**: Female, Male. \n",
    "* **capital-gain**: continuous. \n",
    "* **capital-loss**: continuous. \n",
    "* **hours-per-week**: continuous. \n",
    "* **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data\n",
    "#split the data into features and target label\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income',axis = 1)\n",
    "#Visualize skewed continuous features of original data\n",
    "import visuals as vs\n",
    "vs.distribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log-transform the skewed features\n",
    "skewed = ['capital-gain','capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x:\n",
    "                                                              np.log(x+1))\n",
    "#Visualize the new log distributions\n",
    "# vs.distribution(features_log_transformed,transformed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Normalizing Numerical features in addition to performing transformations on features that are highly skewed,it is often good practice some type of scaling on numerical features.Applying a scaling to the data doesnot change the shape of the feature.Note that once scaling is applied observing the data in its raw form will no longer have the same original meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Initialize a scaler,then apply it to features\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['age','education-num','capital-gain','capital-loss',\\\n",
    "            'hours-per-week']\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform\n",
    "(features_log_transformed[numerical])\n",
    "features_log_minmax_transform.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode the 'features_log_minmax_transform' data using #pandas.get_dummies()\n",
    "\n",
    "features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "\n",
    "#Encode the 'income_raw' data into numerical values\n",
    "income = income_raw.map({'<=50K':0,'>50K':1})\n",
    "\n",
    "#print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding\".format(len(encoded)))\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and Split Data\n",
    "Now all categorical variables have been converted into numerical features\n",
    "and all numerical features have been normalized.As always,we will now split the data(both features and their labels)into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(features_final,income,\\\n",
    "                                                test_size = 0.2,random_state = 0)\n",
    "#show the results of the split\n",
    "print(\"Training set has {} samples:\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples:\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP =np.sum(income) #Counting the ones as this is the naive case.\n",
    "#Note that 'income' is the 'income_raw' data encoded into numerical values\n",
    "#Done in the DataPreprocessing step\n",
    "FP = income.count() - TP #Specific to the naive case\n",
    "TN = 0 #No predicted negatives in the naive case\n",
    "FN = 0 #No predicted negatives\n",
    "\n",
    "#Calculate accuracy,precision and recall\n",
    "accuracy = TP/(TP+FP+TN+FN)\n",
    "recall = TP/(TP + FN)\n",
    "precision = TP/(TP+FP)\n",
    "#calculate F-score using the formula for beta = 0.5\n",
    "beta = 0.5\n",
    "fscore = (1 + beta**2) * ((precision * recall)/((beta**2)*precision + recall))\n",
    "\n",
    "#print the results\n",
    "print(\"Naive Predictor: [Accuracy Score: {:.4f},F-Score: {:.4f}]\"\\\n",
    "      .format(accuracy,fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score,accuracy_score\n",
    "\n",
    "def train_predict(learner,sample_size,X_train,y_train,X_test,y_test):\n",
    "    '''\n",
    "    inputs:\n",
    "    -learner : the learning algorithm to be trained and predicted on\n",
    "    -sample_size :the size of samples to be drawn from training set\n",
    "    -X_train :features training set\n",
    "    -y_train : income traing set\n",
    "    -X_test : features testing set\n",
    "    -y_test : income testing test'''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    #fit the learner to the training data using slicing with 'sample_size'\n",
    "    #using .fit(training_features[:],\n",
    "    #training_labels[:]\n",
    "    \n",
    "    start = time()\n",
    "    learner = learner.fit(X_train[:sample_size],y_train[:sample_size])\n",
    "    end = time()\n",
    "    \n",
    "    #calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "    \n",
    "    #get the prediction on the test set(X_test)\n",
    "    start = time()\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time()\n",
    "    \n",
    "    #calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "    \n",
    "    #compute the accuracy on the first 300 training samples \n",
    "    \n",
    "    results['acc_train'] = accuracy_score(y_train[:300],predictions_train)\n",
    "    \n",
    "    #compute the accuacy on the test set using accuracy_score\n",
    "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
    "    \n",
    "    #compute the F-Score for the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300],predictions_train,beta = 0.5)\n",
    "    \n",
    "    results['f_test'] = fbeta_score(y_test,predictions_test,beta = 0.5)\n",
    "    \n",
    "    print(\"{} trained on {} samples:\".format(learner.__class__.__name__,\\\n",
    "                                            sample_size))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#Implementation : Initial Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the three supervised learning models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#initialize the three models\n",
    "random_state = 42\n",
    "\n",
    "clf_A = RandomForestClassifier(random_state=random_state)\n",
    "clf_B =GaussianNB()\n",
    "clf_C = SVC(random_state=random_state)\n",
    "\n",
    "#calculate the number of samples for 1%,10% and 100% of the traing data\n",
    "\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int(len(y_train)/10)\n",
    "samples_1 = int(len(y_train)/100)\n",
    "\n",
    "#collect the results on learners\n",
    "results = {}\n",
    "for clf in [clf_A,clf_B,clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
    "\n",
    "#run metrics visualization for the 3 supervised learing models\n",
    "vs.evaluate(results,accuracy,fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving Results:\n",
    "In this final section,we will choose from the three supervised learning models the best model to use on the data.We will then perform a gridsearch optimization for the model over the entire training set(X_train and y_train) by tuning parameters to improve upon the untuned models F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "#Intialize the classfier\n",
    "clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "#Create the parameters list you wish to apply\n",
    "\n",
    "parameters = {\n",
    "    'max_depth':[10,20,30,40],\n",
    "    'max_features':[2,3],\n",
    "    'min_samples_leaf':[3,4,5], \n",
    "    'min_samples_split':[8,10,12],\n",
    "    'n_estimators':[50,100,150]}\n",
    "\n",
    "scorer = make_scorer(fbeta_score,beta = 0.5)\n",
    "grid_obj = GridSearchCV(estimator = clf,param_grid = parameters,scoring = scorer,n_jobs = -1)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train,y_train)\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "#make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train,y_train).predict(X_test))\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "#Report the before and after scores\n",
    "print(\"Unoptimized model\\n---------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test,predictions)))\n",
    "print(\"F-Score on testing data: {:.4f}\".format(fbeta_score(y_test,predictions,beta =0.5)))\n",
    "\n",
    "print(\"\\nOptimized model\\n-------\")\n",
    "print(\"Final Accuracy score on the testing data: {:.4f}\".\n",
    "     format(accuracy_score(y_test,best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".\n",
    "     format(fbeta_score(y_test,best_predictions,beta = 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importances\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Train the model on the training data \n",
    "model = AdaBoostClassifier().fit(X_train,y_train)\n",
    "\n",
    "#Extract the feature importances using .feature_importances_\n",
    "\n",
    "importances = model.feature_importances_\n",
    "\n",
    "#plot\n",
    "vs.feature_plot(importances,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructs a new estimator with the same parameters,does a deep copy of the model\n",
    "#in an estimator without copying attached data\n",
    "from sklearn.base import clone\n",
    "\n",
    "#Reduce the feature space\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])]]                                                 \n",
    "\n",
    "#Train on the \"best\" model found from gridsearch\n",
    "clf = (clone(best_clf)).fit(X_train_reduced,y_train)\n",
    "#Make new predictions\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "#Report scores\n",
    "print(\"Final model trained on full data\\n---------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test,best_predictions)))\n",
    "print(\"F-Score on testing data: {:.4f}\".format(fbeta_score(y_test,best_predictions,beta =0.5)))\n",
    "print(\"\\nFinal model on reduced data\\n-------\")\n",
    "print(\"Final Accuracy score on the testing data: {:.4f}\".\n",
    "     format(accuracy_score(y_test,reduced_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".\n",
    "     format(fbeta_score(y_test,reduced_predictions,beta = 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
